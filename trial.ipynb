{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "\n",
    "def process_data(path, unk_token=\"#UNK#\"):\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    \n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        raw = f.read()\n",
    "        sentences = raw.strip().split('\\n\\n')\n",
    "\n",
    "    for sentence in sentences:\n",
    "        pairs = sentence.split('\\n')\n",
    "        inner_tokens = []\n",
    "        inner_labels = []\n",
    "        for pair in pairs:\n",
    "            try:\n",
    "                token, label = pair.split(' ')\n",
    "            except:\n",
    "                pass\n",
    "            inner_tokens.append(token)\n",
    "            inner_labels.append(label)\n",
    "\n",
    "        tokens.append(inner_tokens)\n",
    "        labels.append(inner_labels)\n",
    "\n",
    "    unique_tokens = get_unique(tokens)\n",
    "    unique_tokens = unique_tokens + [unk_token]\n",
    "    unique_labels = get_unique(labels)\n",
    "    \n",
    "    return tokens, labels, unique_tokens, unique_labels\n",
    "\n",
    "\n",
    "def dev_open(path):\n",
    "  out = [[]]\n",
    "  f = open(path, \"r\", encoding=\"utf-8\")\n",
    "  lines_in = f.readlines()\n",
    "  for word in lines_in:\n",
    "    if word == \"\\n\":\n",
    "      out.append([])\n",
    "    else:\n",
    "      out[-1].append(word.rstrip())\n",
    "  return out[:-1]\n",
    "\n",
    "def get_unique(nested_list):\n",
    "    flattened_list = [item for sublist in nested_list for item in sublist]\n",
    "    return sorted(list(set(flattened_list)))\n",
    "\n",
    "def estimate_emission_matrix(unique_labels, unique_tokens, tokens, labels, unk_token=\"#UNK#\", k=1):\n",
    "    e_table = np.zeros((len(unique_labels), len(unique_tokens)+1))\n",
    "    \n",
    "    tag_counts = np.zeros(len(unique_labels))\n",
    "    for label_seq in labels:\n",
    "        for label in label_seq:\n",
    "            tag_counts[unique_labels.index(label)] += 1\n",
    "    \n",
    "    for token_seq, label_seq in zip(tokens, labels):\n",
    "        for token, label in zip(token_seq, label_seq):\n",
    "            if token in unique_tokens:\n",
    "                token_index = unique_tokens.index(token)\n",
    "            else:\n",
    "                token_index = unique_tokens.index(unk_token)  \n",
    "            e_table[unique_labels.index(label)][token_index] += 1\n",
    "\n",
    "    for i in range(len(unique_labels)):\n",
    "        e_table[i, -1] += k / (tag_counts[i] + 1)\n",
    "    \n",
    "    e_table /= e_table.sum(axis=1)[:, np.newaxis]\n",
    "    return e_table\n",
    "\n",
    "def predict_labels_words(unique_labels, unique_tokens, e_table, test_data, unk_token=\"#UNK#\"):\n",
    "    predict_label = []\n",
    "    \n",
    "    for sentence in test_data:\n",
    "        inner_predict = []\n",
    "        for word in sentence:\n",
    "            if word not in unique_tokens:\n",
    "                word = unk_token\n",
    "                pred_label = e_table[:, -1]\n",
    "            else:\n",
    "                pred_label = e_table[:, unique_tokens.index(word)]\n",
    "            most_likely_label = unique_labels[np.argmax(pred_label)]\n",
    "            inner_predict.append(most_likely_label)\n",
    "        predict_label.append(inner_predict)\n",
    "    \n",
    "    return predict_label\n",
    "\n",
    "def estimate_transition_matrix(unique_labels, labels):\n",
    "    q_table = np.zeros((len(unique_labels)+1, len(unique_labels)+1))\n",
    "\n",
    "    rows = ['START'] + unique_labels.copy()\n",
    "    cols = unique_labels.copy() + ['STOP']\n",
    "\n",
    "    for labels_seq in labels:\n",
    "        x = copy.deepcopy(labels_seq)\n",
    "        x.insert(0, 'START')\n",
    "        x.append('STOP')\n",
    "\n",
    "        for i in range(len(x)-1):\n",
    "            cur_label = x[i]\n",
    "            next_label = x[i+1]\n",
    "            q_table[rows.index(cur_label)][cols.index(next_label)] += 1\n",
    "\n",
    "    q_table /= q_table.sum(axis=1)[:, np.newaxis]\n",
    "    return q_table\n",
    "\n",
    "def viterbi_algorithm(unique_labels, unique_tokens, sentence, e_table, q_table, unk_token):\n",
    "    n = len(sentence)\n",
    "    sentence = [None] + sentence\n",
    "    m = len(unique_labels)\n",
    "    pi = np.zeros((n+2, m))\n",
    "\n",
    "    unk_index = unique_tokens.index(unk_token)\n",
    "    unk_emission_probs = e_table[:, unk_index] \n",
    "\n",
    "    for j in range(n):\n",
    "        if sentence[j+1] in unique_tokens:\n",
    "            cur_word = sentence[j+1]\n",
    "            cur_word_index = unique_tokens.index(cur_word)\n",
    "        else:\n",
    "            cur_word = unk_token\n",
    "            cur_word_index = unk_index\n",
    "\n",
    "        for cur_index in range(m):\n",
    "            current_e = unk_emission_probs[cur_index] if cur_word == unk_token else e_table[cur_index, cur_word_index]\n",
    "            if j == 0:\n",
    "                current_q = q_table[0, cur_index]\n",
    "                pi[j+1, cur_index] = 1 * current_e * current_q\n",
    "            else:\n",
    "                max_prob = 0\n",
    "                for vIndex in range(m):\n",
    "                    current_q = q_table[vIndex+1, cur_index]\n",
    "                    cur_prob = pi[j, vIndex] * current_e * current_q\n",
    "\n",
    "                    if cur_prob > max_prob:\n",
    "                        max_prob = cur_prob\n",
    "                pi[j+1, cur_index] = max_prob\n",
    "    \n",
    "    max_prob = 0\n",
    "    for prev_index in range(0, m):\n",
    "        current_q = q_table[prev_index+1, -1]\n",
    "        cur_prob = pi[n, prev_index] * current_q\n",
    "        if cur_prob > max_prob:\n",
    "            max_prob = cur_prob\n",
    "    pi[n+1, -1] = max_prob\n",
    "    \n",
    "    y_star = [np.argmax(unk_emission_probs)] * (n+1)\n",
    "    max_prob = 0\n",
    "    \n",
    "    for cur_index in range(0, m):\n",
    "        current_q = q_table[cur_index+1, -1]\n",
    "        cur_prob = pi[n, cur_index] * current_q\n",
    "        \n",
    "        if cur_prob > max_prob:\n",
    "            max_prob = cur_prob\n",
    "            y_star[n] = cur_index\n",
    "    \n",
    "    for j in range(n-1, 0, -1):\n",
    "        max_prob = 0\n",
    "        for cur_index in range(0, m):\n",
    "            current_q = q_table[cur_index+1, y_star[j+1]]\n",
    "            cur_prob = pi[j, cur_index] * current_q\n",
    "            if cur_prob > max_prob:\n",
    "                max_prob = cur_prob\n",
    "                y_star[j] = cur_index\n",
    "    \n",
    "    labelled_preds = [unique_labels[y] for y in y_star[1:]]\n",
    "    return labelled_preds\n",
    "\n",
    "def predict_labels_sentences(unique_labels, unique_tokens, q_table, e_table, test_data, unk_token):\n",
    "    total_preds = []\n",
    "\n",
    "    for sentence in test_data:\n",
    "        preds = viterbi_algorithm(unique_labels, unique_tokens, sentence, e_table, q_table, unk_token)\n",
    "        total_preds.append(preds)\n",
    "\n",
    "    return total_preds\n",
    "\n",
    "def p1(test_data, predict_label_p1, output_path):\n",
    "    with open(output_path, 'w', encoding='utf-8') as outp:\n",
    "        for sentence, predictions in zip(test_data, predict_label_p1):\n",
    "            for word, pos in zip(sentence, predictions):\n",
    "                result = word + \" \" + pos + \"\\n\"\n",
    "                outp.write(result)\n",
    "            outp.write('\\n')\n",
    "\n",
    "\n",
    "def p2(test_data, predict_label_p2, output_path):\n",
    "    with open(output_path, 'w', encoding='utf-8') as outp:\n",
    "        for sentence, predictions in zip(test_data, predict_label_p2):\n",
    "            for word, pos in zip(sentence, predictions):\n",
    "                result = word + \" \" + pos + \"\\n\"\n",
    "                outp.write(result)\n",
    "            outp.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kthbest_viterbi(e_table, q_table, unique_tokens, unique_labels, unk_token, sentence, num):\n",
    "    k = num\n",
    "    n = len(sentence)\n",
    "    sentence = [None] + sentence\n",
    "    m = len(unique_labels)\n",
    "    pi = np.zeros((n+2, m, k))\n",
    "\n",
    "    for j in range(n):\n",
    "        if sentence[j+1] in unique_tokens:\n",
    "            cur_word = sentence[j+1]\n",
    "        else:\n",
    "            cur_word = unk_token\n",
    "\n",
    "        for cur_index in range(0, m):\n",
    "            current_e = e_table[cur_index, unique_tokens.index(cur_word)]\n",
    "            if j == 0:\n",
    "                current_q = q_table[0, cur_index]\n",
    "                pi[j+1, cur_index, :] = 1 * current_e * current_q\n",
    "            else:\n",
    "                max_probs = []\n",
    "                for prev_index in range(0, m):\n",
    "                    for r in range(k):\n",
    "                        current_q = q_table[prev_index+1, cur_index]\n",
    "                        cur_prob = pi[j, prev_index, r] * current_e * current_q\n",
    "                        max_probs.append(cur_prob)\n",
    "                max_probs.sort(reverse=True)\n",
    "\n",
    "                if len(max_probs) > k:\n",
    "                    max_probs = max_probs[:k]\n",
    "                pi[j+1, cur_index] = max_probs\n",
    "\n",
    "    max_probs = []\n",
    "    for prev_index in range(0, m):\n",
    "        for r in range(k):\n",
    "            current_q = q_table[prev_index+1, -1]\n",
    "            cur_prob = pi[-1, prev_index, r] * current_q\n",
    "            max_probs.append(cur_prob)\n",
    "\n",
    "    max_probs.sort(reverse=True)\n",
    "    if len(max_probs) > k:\n",
    "        max_probs = max_probs[:k]\n",
    "    pi[n+1, -1] = max_probs\n",
    "\n",
    "    yxs = np.zeros((n+1, k), dtype=int) + unique_labels.index(\"O\")\n",
    "    max_probs = []\n",
    "\n",
    "    def take_last(elem):\n",
    "        return elem[-1]\n",
    "\n",
    "    for prev_index in range(0, m):\n",
    "        for r in range(k):\n",
    "            current_q = q_table[prev_index+1, -1]\n",
    "            cur_prob = pi[-1, prev_index, r] * current_q\n",
    "            max_probs.append([prev_index, cur_prob])\n",
    "    max_probs.sort(reverse=True, key=take_last)\n",
    "\n",
    "    def removeRepeated(lst):\n",
    "        new = []\n",
    "        for elem in lst:\n",
    "            if elem[1] != 0 and elem not in new:\n",
    "                new.append(elem)\n",
    "        return new\n",
    "\n",
    "    max_probs = removeRepeated(max_probs)\n",
    "\n",
    "    if len(max_probs) > k:\n",
    "        max_probs = max_probs[:k]\n",
    "\n",
    "    parents = [i[0] for i in max_probs]\n",
    "    yxs[n, :len(max_probs)] = parents\n",
    "\n",
    "    for j in range(n-1, 0, -1):\n",
    "        max_probs = []\n",
    "        for yx in yxs[j+1]:\n",
    "            for cur_index in range(0, m):\n",
    "                for r in range(k):\n",
    "                    current_q = q_table[cur_index+1, yx]\n",
    "                    cur_prob = pi[j, cur_index, r] * current_q\n",
    "                    max_probs.append([cur_index, cur_prob])\n",
    "\n",
    "        max_probs.sort(reverse=True, key=take_last)\n",
    "        max_probs = removeRepeated(max_probs)\n",
    "\n",
    "        if len(max_probs) > k:\n",
    "            max_probs = max_probs[:k]\n",
    "\n",
    "        parents = [i[0] for i in max_probs]\n",
    "        yxs[j, :len(max_probs)] = parents\n",
    "\n",
    "    labelled_preds = [unique_labels[y] for y in yxs.T[-1][1:]]\n",
    "    return labelled_preds\n",
    "\n",
    "def p3(input_path, output_path, unique_labels, unique_tokens, e_table, q_table, unk_token, num):\n",
    "    total_preds = []\n",
    "    data = dev_open(input_path)\n",
    "\n",
    "    for sentence in data:\n",
    "        preds = kthbest_viterbi(e_table, q_table, unique_tokens, unique_labels, unk_token, sentence, num)\n",
    "        total_preds.append(preds)\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as outp:\n",
    "        for _, (token, label) in enumerate(zip(data, total_preds)):\n",
    "            for _, (word, pos) in enumerate(zip(token, label)):\n",
    "                result = word + \" \" + pos + \"\\n\"\n",
    "                outp.write(result)\n",
    "            outp.write('\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_path = \"RU/train\"\n",
    "unk_token = \"#UNK#\"\n",
    "tokens, labels, unique_tokens, unique_labels = process_data(train_path, unk_token)\n",
    "unique_labels = ['O', 'B-positive', 'B-neutral', 'B-negative', 'I-positive', 'I-neutral', 'I-negative']\n",
    "unique_tokens.append(unk_token)\n",
    "\n",
    "\n",
    "e_table = estimate_emission_matrix(unique_labels, unique_tokens, tokens, labels, unk_token, k=1)\n",
    "q_table = estimate_transition_matrix(unique_labels, labels)\n",
    "\n",
    "input_path = \"RU/dev.in\"\n",
    "test_data = dev_open(input_path)\n",
    "\n",
    "predict_label_p1 = predict_labels_words(unique_labels, unique_tokens, e_table, test_data, unk_token)\n",
    "predict_label_p2 = predict_labels_sentences(unique_labels, unique_tokens, q_table, e_table, test_data, unk_token)\n",
    "\n",
    "predict_p1_output_path = \"RU/dev.p7.out\"\n",
    "predict_p2_output_path = \"RU/dev.p8.out\"\n",
    "predict_p3_output_path = \"RU/dev.p9.out\"\n",
    "\n",
    "p1(test_data, predict_label_p1, predict_p1_output_path)\n",
    "p2(test_data, predict_label_p2, predict_p2_output_path)\n",
    "\n",
    "num = 2\n",
    "p3(input_path,  predict_p3_output_path, unique_labels, unique_tokens, e_table, q_table, unk_token, num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
