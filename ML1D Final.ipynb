{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Libraries**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions for Part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_prediction(prediction, data, path):\n",
    "    assert(len(prediction) == len(data))\n",
    "    file = open(path, \"w\", encoding=\"utf-8\")\n",
    "    n = len(data)\n",
    "    print(\"Writing\", n, \"lines\")\n",
    "    for i in range(n):\n",
    "        assert(len(data[i]) == len(prediction[i]))\n",
    "        m = len(data[i])\n",
    "        for j in range(m):\n",
    "            file.write(data[i][j] + \" \" + prediction[i][j] + \"\\n\")\n",
    "        file.write(\"\\n\")\n",
    "    print(\"Wrote predictions to\", path)\n",
    "\n",
    "def get_training_set_words(data):\n",
    "    words = set()\n",
    "    for i in data:\n",
    "        if len(data) > 1:\n",
    "            words.add(i[0])\n",
    "    return words\n",
    "\n",
    "def dev_open(path):\n",
    "  out = [[]]\n",
    "  f = open(path, \"r\", encoding=\"utf-8\")\n",
    "  lines_in = f.readlines()\n",
    "  for word in lines_in:\n",
    "    if word == \"\\n\":\n",
    "      out.append([])\n",
    "    else:\n",
    "      out[-1].append(word.rstrip())\n",
    "  return out[:-1]\n",
    "\n",
    "\n",
    "def count_words_not_in_train(dev_data, train_words):\n",
    "    words_not_in_train = 0\n",
    "    for sentence in dev_data:\n",
    "        for word in sentence:\n",
    "            if word not in train_words:\n",
    "                words_not_in_train += 1\n",
    "    return words_not_in_train\n",
    "\n",
    "\n",
    "def read_data(path):\n",
    "  dataset = []\n",
    "  f = open(path,\"r\", encoding=\"utf-8\")\n",
    "  training_set = f.readlines()\n",
    "  for line in training_set:\n",
    "    if len(line) == 1:\n",
    "      dataset.append(\"\\n\")\n",
    "    else:\n",
    "      line = line.rstrip('\\n')\n",
    "      line = line.rpartition(' ')\n",
    "      line = list(line)\n",
    "      del line[1]\n",
    "      if line != ['', '']:\n",
    "        dataset.append(line)\n",
    "  Edataset = [ele for ele in dataset]\n",
    "  return Edataset\n",
    "\n",
    "\n",
    "def count_tags(training_set):\n",
    "  unique_tag_count = {'START':0,'O':0,'B-positive':0,'B-neutral':0,'B-negative':0,'I-positive':0,'I-neutral':0,'I-negative':0,'STOP':0}\n",
    "  for data_pair in training_set:\n",
    "    if len(data_pair) > 1:\n",
    "      if data_pair[1] in unique_tag_count.keys():\n",
    "        unique_tag_count[data_pair[1]] += 1\n",
    "    elif len(data_pair)==1:\n",
    "      unique_tag_count['START'] += 1 \n",
    "      unique_tag_count['STOP'] += 1\n",
    "  return unique_tag_count\n",
    "\n",
    "\n",
    "def count_words_for_each_tag(training_set):\n",
    "  label_generate_all = {'O':{},'B-positive':{},'B-neutral':{},'B-negative':{},'I-positive':{},'I-neutral':{},'I-negative':{}}\n",
    "  for data in training_set:\n",
    "    if len(data) > 1:\n",
    "        if data[0] not in label_generate_all[data[1]].keys():\n",
    "          label_generate_all[data[1]][data[0]] = 1\n",
    "        else:\n",
    "          label_generate_all[data[1]][data[0]] += 1 \n",
    "\n",
    "  return label_generate_all\n",
    "\n",
    "\n",
    "def get_tags(data):\n",
    "    unique_labels = set()\n",
    "    for sentence in data:\n",
    "        for _, label in sentence:\n",
    "            unique_labels.add(label)\n",
    "    return list(unique_labels)\n",
    "\n",
    "\n",
    "def estimate_emission_params(count_tags, count_tag_words, smoothing_factor=1):\n",
    "    emission_params = {}\n",
    "    for tag_tuple, tag_word_counts in count_tag_words.items():\n",
    "        tag_estimations = {}\n",
    "        for word, word_count in tag_word_counts.items():\n",
    "            estimated_value = word_count / (count_tags[tag_tuple] + smoothing_factor)\n",
    "            tag_estimations[word] = estimated_value\n",
    "        tag_estimations['#UNK#'] = smoothing_factor / (count_tags[tag_tuple] + smoothing_factor)\n",
    "        emission_params[tag_tuple] = tag_estimations\n",
    "    \n",
    "    return emission_params\n",
    "\n",
    "\n",
    "def predict_sentiment(words, e_params, word_set):\n",
    "    sentiment_labels = ['O', 'B-positive', 'B-neutral', 'B-negative', 'I-positive', 'I-neutral', 'I-negative']\n",
    "    predictions = []\n",
    "    for word in words:\n",
    "        max_label = 'O'\n",
    "        max_probability = 0\n",
    "        if word not in word_set:\n",
    "            word = \"#UNK#\"\n",
    "        for label in sentiment_labels:\n",
    "            if word not in e_params[label]:\n",
    "                continue\n",
    "            current_prob = e_params[label][word]\n",
    "            if current_prob > max_probability:\n",
    "                max_label = label\n",
    "                max_probability = current_prob\n",
    "        \n",
    "        predictions.append(max_label)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "\n",
    "def make_predictions(data, e_params, word_set):\n",
    "    all_predictions = []\n",
    "    for sentence in data:\n",
    "        all_predictions.append(predict_sentiment(sentence, e_params, word_set))\n",
    "    \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calling functions, estimating emission params and tagging words for RU dev.in**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 437 lines\n",
      "Wrote predictions to RU/dev.p1.out\n"
     ]
    }
   ],
   "source": [
    "train_path_RU = \"RU/train\"\n",
    "test_path_RU = \"RU/dev.in\"\n",
    "output_path_RU = \"RU/dev.p1.out\"\n",
    "train_data_RU = read_data(train_path_RU)\n",
    "train_words_RU = get_training_set_words(train_data_RU)\n",
    "tag_counts_RU = count_tags(train_data_RU)\n",
    "test_data_RU = dev_open(test_path_RU)\n",
    "tags_RU = count_tags(train_data_RU)\n",
    "tag_word_counts_RU = count_words_for_each_tag(train_data_RU)\n",
    "emission_params_RU = estimate_emission_params(tag_counts_RU, tag_word_counts_RU)\n",
    "predictions_RU = make_predictions(test_data_RU, emission_params_RU, train_words_RU)\n",
    "output_prediction(predictions_RU, test_data_RU, output_path_RU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calling functions, estimating emission params and tagging words for ES dev.in**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 266 lines\n",
      "Wrote predictions to ES/dev.p1.out\n"
     ]
    }
   ],
   "source": [
    "train_path_ES = \"ES/train\"\n",
    "test_path_ES = \"ES/dev.in\"\n",
    "output_path_ES = \"ES/dev.p1.out\"\n",
    "output_path_part_2_ES = \"ES/dev.p2.out\"\n",
    "train_data_ES = read_data(train_path_ES)\n",
    "train_words_ES = get_training_set_words(train_data_ES)\n",
    "tag_counts_ES = count_tags(train_data_ES)\n",
    "test_data_ES = dev_open(test_path_ES)\n",
    "tags_ES = count_tags(train_data_ES)\n",
    "tag_word_counts_ES = count_words_for_each_tag(train_data_ES)\n",
    "emission_params_ES = estimate_emission_params(tag_counts_ES, tag_word_counts_ES)\n",
    "predictions_ES = make_predictions(test_data_ES, emission_params_ES, train_words_ES)\n",
    "output_prediction(predictions_ES, test_data_ES, output_path_ES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions for Part 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_transition_parameters(data, tag_counts):\n",
    "    transition_counts = {'START': {}, 'O': {}, 'B-positive': {}, 'B-neutral': {}, 'B-negative': {}, 'I-positive': {}, 'I-neutral': {}, 'I-negative': {}}\n",
    "    \n",
    "    for label in transition_counts.keys():\n",
    "        transition_counts[label] = {'O': 0, 'B-positive': 0, 'B-neutral': 0, 'B-negative': 0, 'I-positive': 0, 'I-neutral': 0, 'I-negative': 0, 'STOP': 0}\n",
    "    \n",
    "    last_position = 'START'\n",
    "    \n",
    "    for line in data:\n",
    "        if line == \"\\n\":\n",
    "            transition_counts[last_position][\"STOP\"] += 1\n",
    "            last_position = 'START'\n",
    "        else:\n",
    "            next_label = line[1]\n",
    "            transition_counts[last_position][next_label] += 1\n",
    "            last_position = next_label\n",
    "    \n",
    "    transition_probabilities = {'START': {}, 'O': {}, 'B-positive': {}, 'B-neutral': {}, 'B-negative': {}, 'I-positive': {}, 'I-neutral': {}, 'I-negative': {}, 'STOP': {}}\n",
    "    \n",
    "    for label_in in transition_probabilities.keys():\n",
    "        transition_probabilities[label_in] = {'START': 0, 'O': 0, 'B-positive': 0, 'B-neutral': 0, 'B-negative': 0, 'I-positive': 0, 'I-neutral': 0, 'I-negative': 0, 'STOP': 0}\n",
    "    \n",
    "    for label_in, t_counts in transition_counts.items():\n",
    "        for label_out, count in t_counts.items():\n",
    "            transition_probabilities[label_in][label_out] = count / tag_counts[label_in]\n",
    "    \n",
    "    return transition_probabilities\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def viterbi_algo(data, trans_probs, emiss_probs, vocab):\n",
    "    n = len(data)\n",
    "    labels = ['O', 'B-positive', 'B-neutral', 'B-negative', 'I-positive', 'I-neutral', 'I-negative', 'START']\n",
    "\n",
    "    n_inf = -math.inf\n",
    "    memo = [{'START': [n_inf, None],\n",
    "             'STOP': [n_inf, None], \n",
    "             'O': [n_inf, None],\n",
    "             'B-positive': [n_inf, None],\n",
    "             'B-neutral': [n_inf, None],\n",
    "             'B-negative': [n_inf, None],\n",
    "             'I-positive': [n_inf, None],\n",
    "             'I-neutral': [n_inf, None],\n",
    "             'I-negative': [n_inf, None]} for i in range(n + 2)]\n",
    "\n",
    "    memo[0]['START'][0] = 0 \n",
    "\n",
    "    for j in range(0, n):\n",
    "        next_wd = data[j]\n",
    "\n",
    "        for u in labels:\n",
    "            max_val = n_inf\n",
    "            max_lbl = None\n",
    "            for v in labels:\n",
    "                if (memo[j][v][0] == n_inf or trans_probs[v][u] == 0):\n",
    "                    continue\n",
    "                prev_val = memo[j][v][0]\n",
    "                if next_wd in vocab:\n",
    "                    if next_wd not in emiss_probs[u].keys():\n",
    "                        continue\n",
    "                    else:\n",
    "                        em_prob = emiss_probs[u][next_wd]\n",
    "                else:\n",
    "                    em_prob = emiss_probs[u]['#UNK#']\n",
    "                trans_prob = trans_probs[v][u]\n",
    "                prob = prev_val + math.log(em_prob) + math.log(trans_prob)\n",
    "                if max_val < prob:\n",
    "                    max_val = prob\n",
    "                    max_lbl = v\n",
    "            \n",
    "            if max_val == n_inf:\n",
    "                continue\n",
    "            memo[j + 1][u][0] = max_val\n",
    "            memo[j + 1][u][1] = max_lbl\n",
    "    \n",
    "    max_val = n_inf\n",
    "    max_lbl = None\n",
    "    for v in labels:\n",
    "        prev_val = memo[n][v][0]\n",
    "        trans_prob = trans_probs[v]['STOP']\n",
    "        if (prev_val == 0 or trans_prob == 0):\n",
    "            continue\n",
    "        prob = prev_val + math.log(trans_prob)\n",
    "        if max_val < prob:\n",
    "            max_val = prob\n",
    "            max_lbl = v\n",
    "\n",
    "    if max_val != n_inf:\n",
    "        memo[n + 1]['STOP'][0] = max_val\n",
    "        memo[n + 1]['STOP'][1] = max_lbl\n",
    "\n",
    "    output = ['' for i in range(n)]\n",
    "\n",
    "    if max_lbl == None:\n",
    "        max_lbl = \"O\"\n",
    "\n",
    "    for j in range(n + 1, 1, -1):\n",
    "        max_lbl = memo[j][max_lbl][1]\n",
    "        if max_lbl == None:\n",
    "            max_lbl = \"O\"\n",
    "        output[j - 2] = max_lbl\n",
    "    \n",
    "    return output\n",
    "\n",
    "def viterbi_call(sep_data, trans_probs, emiss_probs, vocab):\n",
    "    final_result = []\n",
    "    for doc in sep_data:\n",
    "        final_result.append(viterbi_algo(doc, trans_probs, emiss_probs, vocab))\n",
    "    return final_result\n",
    "\n",
    "\n",
    "def viterbi_to_file(test, predictions, output_path):\n",
    "    tags = []\n",
    "    text = []\n",
    "    \n",
    "    for prediction in predictions:\n",
    "        for tag in prediction:\n",
    "            tags.append(tag)\n",
    "\n",
    "    for words in test:\n",
    "        for word in words:\n",
    "            text.append(word)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        0: text,\n",
    "        1: tags\n",
    "    })\n",
    "    \n",
    "    df.to_csv(output_path, sep='\\t', index=False)\n",
    "    print(f\"Output written to {output_path}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calling functions for part 2 RU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output written to RU/dev.p2.out\n"
     ]
    }
   ],
   "source": [
    "output_path_part_2_RU = \"RU/dev.p2.out\"\n",
    "transition_params_RU = estimate_transition_parameters(train_data_RU, tag_counts_RU)\n",
    "prediction_RU = viterbi_call(test_data_RU, transition_params_RU, emission_params_RU, train_words_RU)\n",
    "result_RU = viterbi_to_file(test_data_RU, prediction_RU, output_path_part_2_RU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calling functions for part 2 ES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output written to RU/dev.p2.out\n"
     ]
    }
   ],
   "source": [
    "output_path_part_2_RU = \"RU/dev.p2.out\"\n",
    "transition_params_RU = estimate_transition_parameters(train_data_RU, tag_counts_RU)\n",
    "prediction_RU = viterbi_call(test_data_RU, transition_params_RU, emission_params_RU, train_words_RU)\n",
    "result_RU = viterbi_to_file(test_data_RU, prediction_RU, output_path_part_2_RU)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Desktop-6cMZ7Q1n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
